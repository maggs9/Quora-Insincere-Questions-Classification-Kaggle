{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/meghana.negi/.local/share/virtualenvs/Quora-Insincere-Questions-Classification-K-VOuQS9ZU/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "## Load Embeddings\n",
    "## 1. Glove\n",
    "import pandas as pd\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## Keras import\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "## CNN\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "sub = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209967 unique words\n"
     ]
    }
   ],
   "source": [
    "## Pre Processing\n",
    "all_sentence = pd.concat([train[\"question_text\"], test[\"question_text\"]])\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ \\'')\n",
    "tokenizer.fit_on_texts(all_sentence)\n",
    "word_dict = tokenizer.word_index\n",
    "print(\"Found %s unique words\" % len(word_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = len(word_dict)\n",
    "embed_size=300\n",
    "\n",
    "def make_embedding_matrix(word_vec):\n",
    "    embedding = np.zeros((nb_words+1, embed_size))\n",
    "    for word, i in word_dict.items():\n",
    "        vec = word_vec.get(word)\n",
    "        if vec is not None: embedding[i] = vec\n",
    "    return embedding\n",
    "\n",
    "def loadEmbeddings(name):\n",
    "    embeddings_index = {}\n",
    "    if name == \"glove\":\n",
    "        f = open('./embedding/glove.840B.300d.txt')\n",
    "        for line in f:\n",
    "            values = line.split(\" \")\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        \n",
    "    if name == \"google\":\n",
    "        model = KeyedVectors.load_word2vec_format('./embedding/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "        vocab = model.vocab.keys()\n",
    "        for word in vocab:\n",
    "            embeddings_index[word] = model.wv[word]\n",
    "        del model\n",
    "        del vocab\n",
    "        #print('Found %s word vectors.' % len(vocab))\n",
    "        \n",
    "    if name == \"paragram\":\n",
    "        print(\"paragram\")\n",
    "        EMBEDDING_FILE = './embedding/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "        f = open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore')\n",
    "        for line in f:\n",
    "            values = line.split(\" \")\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    if name == \"wiki\":\n",
    "        EMBEDDING_FILE = './embedding/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "        f = open(EMBEDDING_FILE)\n",
    "        #print(\"wiki\")\n",
    "        for line in f:\n",
    "            values = line.split(\" \")\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "    embedding_matrix = make_embedding_matrix(embeddings_index)\n",
    "    del embeddings_index\n",
    "    return embedding_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghana.negi/.local/share/virtualenvs/Quora-Insincere-Questions-Classification-K-VOuQS9ZU/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "## Load Embeddings\n",
    "\n",
    "embedding_matrix_wordvec = loadEmbeddings(\"google\")\n",
    "embedding_matrix_glove = loadEmbeddings(\"glove\")\n",
    "\n",
    "## ADD more more Channel \n",
    "## memory Constraints - Adding only one\n",
    "#embedding_matrix_wiki  = loadEmbeddings(\"wiki\")\n",
    "#embedding_matrix_paragram = loadEmbeddings(\"paragram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "EMBEDDING_DIM = 300\n",
    "sequence_length = 30\n",
    "vocab_size = nb_words+1\n",
    "\n",
    "batch_size_train = 128\n",
    "filter_sizes = [2,3,4,5,6]\n",
    "num_filters = 10\n",
    "drop = 0.2\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n"
     ]
    }
   ],
   "source": [
    "## Model Defination\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    inputs_sent = Input(shape=(sequence_length,), dtype='int32')\n",
    "    \n",
    "    ## Embedding 1 - GLOVE\n",
    "    embedding_1 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length,  weights=[embedding_matrix_glove])(inputs_sent)\n",
    "\n",
    "    input_re_1 = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding_1)\n",
    "\n",
    "    conv_1_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_1)\n",
    "    conv_1_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_1)\n",
    "    conv_1_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_1)\n",
    "    conv_1_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_1)\n",
    "\n",
    "\n",
    "    maxpool_1_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_1_0)\n",
    "    maxpool_1_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1_1)\n",
    "    maxpool_1_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_1_2)\n",
    "    maxpool_1_3 = MaxPool2D(pool_size=(sequence_length - filter_sizes[3] + 1, 1), strides=(1,1), padding='valid')(conv_1_3)\n",
    "    \n",
    "    ## Embedding 2 - Google - word2Vec\n",
    "    embedding_2 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length, weights=[embedding_matrix_wordvec])(inputs_sent)\n",
    "    input_re_2 = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding_2)\n",
    "\n",
    "    conv_2_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_2)\n",
    "    conv_2_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_2)\n",
    "    conv_2_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_2)\n",
    "    conv_2_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_2)\n",
    "\n",
    "\n",
    "    maxpool_2_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_2_0)\n",
    "    maxpool_2_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_2_1)\n",
    "    maxpool_2_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2_2)\n",
    "    maxpool_2_3 = MaxPool2D(pool_size=(sequence_length - filter_sizes[3] + 1, 1), strides=(1,1), padding='valid')(conv_2_3)\n",
    "    \n",
    "    ## Embedding 1 - WIKI (Reparting Glove since we dont have enoght memory, This time changing filter size)\n",
    "    #embedding_3 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length,  weights=[ebedding_matrix_wiki])(inputs_sent)\n",
    "    embedding_3 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length,  weights=[embedding_matrix_glove])(inputs_sent)\n",
    "\n",
    "\n",
    "    input_re_3 = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding_3)\n",
    "\n",
    "    conv_3_0 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_3)\n",
    "    conv_3_1 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_3)\n",
    "    conv_3_2 = Conv2D(num_filters, kernel_size=(filter_sizes[3], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_3)\n",
    "    conv_3_3 = Conv2D(num_filters, kernel_size=(filter_sizes[4], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_3)\n",
    "\n",
    "\n",
    "    maxpool_3_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_3_0)\n",
    "    maxpool_3_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_3_1)\n",
    "    maxpool_3_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[3] + 1, 1), strides=(1,1), padding='valid')(conv_3_2)\n",
    "    maxpool_3_3 = MaxPool2D(pool_size=(sequence_length - filter_sizes[4] + 1, 1), strides=(1,1), padding='valid')(conv_3_3)\n",
    "    \n",
    "    ## Embedding 1 - PARAGRAM (Reparting Word2vec since we dont have enoght memory, This time changing filter size)\n",
    "    #embedding_4 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length,  weights=[embedding_matrix_paragram])(inputs_sent)\n",
    "    embedding_4 = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=sequence_length,  weights=[embedding_matrix_wordvec])(inputs_sent)\n",
    "\n",
    "    input_re_4 = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding_4)\n",
    "\n",
    "    conv_4_0 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_4)\n",
    "    conv_4_1 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_4)\n",
    "    conv_4_2 = Conv2D(num_filters, kernel_size=(filter_sizes[3], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_4)\n",
    "    conv_4_3 = Conv2D(num_filters, kernel_size=(filter_sizes[4], EMBEDDING_DIM), padding='valid', kernel_initializer='he_normal', activation='relu')(input_re_4)\n",
    "\n",
    "\n",
    "    maxpool_4_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_4_0)\n",
    "    maxpool_4_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_4_1)\n",
    "    maxpool_4_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[3] + 1, 1), strides=(1,1), padding='valid')(conv_4_2)\n",
    "    maxpool_4_3 = MaxPool2D(pool_size=(sequence_length - filter_sizes[4] + 1, 1), strides=(1,1), padding='valid')(conv_4_3)\n",
    "    \n",
    "\n",
    "    ## CONCATINATION OF ALL\n",
    "\n",
    "    concatenated_tensor = Concatenate(axis=1)([maxpool_1_0,maxpool_1_1, maxpool_1_2, maxpool_1_3,\n",
    "                                               maxpool_2_0, maxpool_2_1, maxpool_2_2,maxpool_2_3,\n",
    "                                               maxpool_3_0, maxpool_3_1, maxpool_3_2,maxpool_3_3,\n",
    "                                               maxpool_4_0, maxpool_4_1, maxpool_4_2,maxpool_4_3,\n",
    "                                              ])\n",
    "    flatten = Flatten()(concatenated_tensor)\n",
    "    #drop_out = Dropout(0.1)(flatten)\n",
    "    output_prob = Dense(units=1, activation='sigmoid')(flatten)\n",
    "    \n",
    "    model = Model(inputs=inputs_sent, outputs=output_prob)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    #checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    print(\"Model Created\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# this creates a model\n",
    "model= create_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(text):\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    data = pad_sequences(sequences, padding = \"post\", maxlen=sequence_length)\n",
    "    return (sequences,data[0])\n",
    "\n",
    "def batch_gen_train_cnn(data,batch_size, text_column,label_column):\n",
    "    n_batches = math.ceil(len(data)/batch_size)\n",
    "    while True:\n",
    "        data = data.sample(frac = 1.0) ## resuffle\n",
    "        for i in range(n_batches):\n",
    "            sample_data = data[batch_size*i:batch_size*(i+1)]\n",
    "            wrd_vec = np.array([preProcessing([X_text])[1] for X_text in sample_data[text_column]])\n",
    "            lable_indx = np.array(sample_data[label_column])\n",
    "            yield wrd_vec,lable_indx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model...\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 521s 5s/step - loss: 0.1392 - acc: 0.9452 - val_loss: 0.1368 - val_acc: 0.9477\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 529s 5s/step - loss: 0.1283 - acc: 0.9507 - val_loss: 0.1448 - val_acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2670abe80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train and Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_train , split_val = train_test_split(train, test_size = 0.2)\n",
    "train_batch = batch_gen_train_cnn(split_train,batch_size_train,\"question_text\",\"target\")\n",
    "val_batch = batch_gen_train_cnn(split_val,batch_size_train,\"question_text\",\"target\")\n",
    "\n",
    "print(\"Traning Model...\")\n",
    "#no_validation_steps = int(len(split_val)/batch_size_train)\n",
    "#steps_epoch_train = int(len(split_train)/batch_size_train)\n",
    "steps_epoch_train=100\n",
    "no_validation_steps = 10\n",
    "model.fit_generator(train_batch, epochs=2, steps_per_epoch=steps_epoch_train, validation_data = val_batch, validation_steps = no_validation_steps,verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def batch_gen_test_cnn(data,batch_size, text_column):\n",
    "    n_batches = math.ceil(len(data)/batch_size)\n",
    "    for i in range(n_batches):\n",
    "        sample_data = data[batch_size*i:batch_size*(i+1)]\n",
    "        wrd_vec = np.array([preProcessing([X_text])[1] for X_text in sample_data[text_column]])\n",
    "        yield wrd_vec\n",
    "    \n",
    "batch_size_test=20\n",
    "test_sample = test[:100]\n",
    "test_data_gen = batch_gen_test_cnn(test_sample,batch_size_test,'question_text')      \n",
    "all_preds = []\n",
    "for x in tqdm(test_data_gen):\n",
    "    all_preds.extend(model.predict(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction_prob</th>\n",
       "      <th>q</th>\n",
       "      <th>prediction_5</th>\n",
       "      <th>prediction_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  prediction_prob  \\\n",
       "0  00014894849d00ba98a9         0.009947   \n",
       "1  000156468431f09b3cae         0.001019   \n",
       "2  000227734433360e1aae         0.002606   \n",
       "3  0005e06fbe3045bd2a92         0.023742   \n",
       "4  00068a0f7f41f50fc399         0.005262   \n",
       "\n",
       "                                                   q prediction_5 prediction_3  \n",
       "0  My voice range is A2-C5. My chest voice goes u...            0            0  \n",
       "1           How much does a tutor earn in Bangalore?            0            0  \n",
       "2  What are the best made pocket knives under $20...            0            0  \n",
       "3  Why would they add a hypothetical scenario tha...            0            0  \n",
       "4   What is the dresscode for Techmahindra freshers?            0            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = pd.DataFrame({\"qid\": test_sample[\"qid\"], \"prediction_prob\": all_preds,\"q\":test_sample[\"question_text\"]})\n",
    "submit_df[\"prediction_5\"] = np.where(submit_df['prediction_prob']>0.5, '1', '0')\n",
    "submit_df[\"prediction_3\"] = np.where(submit_df['prediction_prob']>0.3, '1', '0')\n",
    "\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction_prob</th>\n",
       "      <th>q</th>\n",
       "      <th>prediction_5</th>\n",
       "      <th>prediction_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>003069ba70645b15c3ba</td>\n",
       "      <td>0.510671</td>\n",
       "      <td>Why don't India start a War with Pakistan ? Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>005af7396a84a515f67c</td>\n",
       "      <td>0.356680</td>\n",
       "      <td>Are Hindus allowed to build new temples in Pak...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0061c39bba71f03ac780</td>\n",
       "      <td>0.547797</td>\n",
       "      <td>Why do people think white privilege is real wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0069468befb619ce22c6</td>\n",
       "      <td>0.373943</td>\n",
       "      <td>Is the Indian Fuhrer capable of operating a sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>007e65e4441890f4416b</td>\n",
       "      <td>0.570884</td>\n",
       "      <td>Why does Quora send me a notice because I told...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qid  prediction_prob  \\\n",
       "39  003069ba70645b15c3ba         0.510671   \n",
       "69  005af7396a84a515f67c         0.356680   \n",
       "77  0061c39bba71f03ac780         0.547797   \n",
       "86  0069468befb619ce22c6         0.373943   \n",
       "98  007e65e4441890f4416b         0.570884   \n",
       "\n",
       "                                                    q prediction_5  \\\n",
       "39  Why don't India start a War with Pakistan ? Th...            1   \n",
       "69  Are Hindus allowed to build new temples in Pak...            0   \n",
       "77  Why do people think white privilege is real wh...            1   \n",
       "86  Is the Indian Fuhrer capable of operating a sm...            0   \n",
       "98  Why does Quora send me a notice because I told...            1   \n",
       "\n",
       "   prediction_3  \n",
       "39            1  \n",
       "69            1  \n",
       "77            1  \n",
       "86            1  \n",
       "98            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df[submit_df.prediction_3=='1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
